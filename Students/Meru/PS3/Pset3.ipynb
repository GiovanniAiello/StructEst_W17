{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE estimation of a simple macroeconomic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe time series data in an economy for the following variables $(c_t, k_t, w_t, r_t)$. The first line of this file contains variable labels. These data have 100 periods, which are quarterly (25 years). Suppose you think the data are generated by a pricess similar to the Brock and Mirman (1972). A simplified set of characterizing equations of the Brock and Mirman model are the following:\n",
    "\\begin{align}\n",
    "c_t^{-1} - \\beta E[r_{t+1}(c_{t+1})^{-1}] & = 0 && \\text{(1)} \\\\\n",
    "c_t - k_{t+1} - w_t - r_t k_t & = 0 && \\text{(2)} \\\\\n",
    "w_t - (1-\\alpha)e^{z_t}k_t^\\alpha & = 0 && \\text{(3)} \\\\\n",
    "r_t - \\alpha e^{z_t} k_t^{\\alpha - 1} & = 0 && \\text{(4)} \\\\\n",
    "z_t & = \\rho z_{t-1} + (1-\\rho)\\mu + \\epsilon_t && \\text{(5)} \\\\\n",
    "\\epsilon_t & \\sim N(0,\\sigma^2)\n",
    "\\end{align}\n",
    "The variable $c_t$ is aggregate consumption in period $t$. $k_{t+1}$ is total household savings and investment in period $t$ for which they receive a return in the next period (this model assumes full depreciation of capital). The wage per unit of labor in period $t$ is $w_t$ adn the interest rate or rate of return on investment is $r_t$. Total factor productivity is $z_t$, which follows an AR(1) process. The rest of the symbols in the equations are parameters that must be estimated:\n",
    "$$ (\\alpha, \\beta, \\rho, \\mu, \\sigma) $$\n",
    "The constraints on these parameters are:\n",
    "$$ \\alpha, \\beta \\in (0,1), \\quad \\mu,\\sigma > 0, \\quad \\rho \\in (-1,1) $$\n",
    "Assume that the first observation in the data file is $t=1$. Let $k_1$ be the first observation in the data file for $k_t$. Assume that $z_0 = \\mu$, so that $z_1 = \\mu$. Assume that the discount factor is known to be $\\beta = 0.99$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Modules\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import scipy.special as spc\n",
    "import scipy.integrate as integrate\n",
    "import distributions as dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Data\n",
    "macroseries = pd.read_csv('MacroSeries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Use the data $(w_t,k_t)$ and equations (3) and (5) to estimate the four parameters $(\\alpha, \\rho, \\mu, \\sigma)$ by maximum likelihood. Given a guess for the parameters $(\\alpha, \\rho, \\mu, \\sigma)$, you can use the two variables from the data $(w_t,k_t)$ and (3) to back out a series for $z_t$. You can then use equation (5) to compute the probability of each \n",
    "$$ z_t \\sim N(\\rho z_{t-1} + (1-\\rho) \\mu, \\sigma^2) $$\n",
    "The maximum likelihood estimate $(\\hat{\\alpha},\\hat{\\rho},\\hat{\\mu},\\hat{\\sigma})$ maximzies the likelihood function of that normal distribution of $z_t$'s. Report your estimates and the inverse hessian variance-covariance matrix of your estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.3667071645704"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define z_t using (3)\n",
    "def z_t(w_t,k_t,alpha):\n",
    "    return np.log(w_t/((1-alpha)*k_t**alpha))\n",
    "\n",
    "def epsilon_t(z_t, rho,mu):\n",
    "    z_t_1 = z_t.shift()\n",
    "    z_t_1[0] = mu\n",
    "    return z_t - rho*z_t_1 - (1-rho)*mu\n",
    "\n",
    "# Define log likelihood function\n",
    "def log_lik_norm(w_t,k_t, alpha, rho, mu, sigma):\n",
    "    epsilonvals = epsilon_t(z_t(w_t,k_t,alpha), rho,mu)\n",
    "    ln_pdf_vals = np.log(dst.norm_pdf(epsilonvals,0,sigma))\n",
    "    #ln_pdf_vals = -((epsilonvals)**2)/(2*sigma**2) - (1/2)*np.log(2*np.pi*sigma**2)\n",
    "    #ln_pdf_vals = np.log(sts.norm.pdf(epsilonvals,loc=0,scale=sigma))\n",
    "    return ln_pdf_vals.sum()\n",
    "\n",
    "# Define Objective Function\n",
    "def crit(params, w_t, k_t):\n",
    "    alpha, rho, mu, sigma = params\n",
    "    log_lik_val = log_lik_norm(w_t,k_t, alpha, rho, mu, sigma)\n",
    "    return -log_lik_val\n",
    "\n",
    "### Various Tests\n",
    "#epsilon_t(z_t(macroseries[\"w_t\"],macroseries[\"k_t\"],alpha_0), rho_0,mu_0)[1:]\n",
    "#log_lik_norm(macroseries[\"w_t\"],macroseries[\"k_t\"], alpha_0, rho_0, mu_0, sigma_0)\n",
    "#crit(np.array([alpha_0, rho_0, mu_0, sigma_0]), macroseries[\"w_t\"],macroseries[\"k_t\"])\n",
    "#macroseries[\"w_t\"],macroseries[\"k_t\"]\n",
    "#z_t(macroseries[\"w_t\"],macroseries[\"k_t\"],.5), z_t(macroseries[\"w_t\"],macroseries[\"k_t\"],.5).shift()\n",
    "#check = z_t(macroseries[\"w_t\"],macroseries[\"k_t\"],.5).shift()\n",
    "#check[0] = .5\n",
    "#print(check)\n",
    "crit(np.array([0.911802782775,  0.999999999999,  1.03857989199, 1.04649469512]), macroseries[\"w_t\"],macroseries[\"k_t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Maximum Likelihood with Gamma\n",
    "alpha_0, rho_0, mu_0, sigma_0 = .5, 0, .5, .5\n",
    "#alpha_0, rho_0, mu_0, sigma_0 = 0.46087855,  0.71646589,  9.47567957,  0.09206664\n",
    "params_init = np.array([alpha_0, rho_0, mu_0, sigma_0])\n",
    "mle_args = (macroseries[\"w_t\"],macroseries[\"k_t\"])\n",
    "results1 = opt.minimize(crit, params_init, args=mle_args, method = \"L-BFGS-B\",\n",
    "                        bounds = ((1e-8, 1-1e-8), (-1+1e-8, 1-1e-8), (1e-8, None), (1e-8, None)), options ={'ftol': 1e-10})\n",
    "alpha_MLE, rho_MLE, mu_MLE, sigma_MLE = results1.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_MLE= 0.92199196448  rho_MLE= 0.99999999 mu_MLE= 0.8384721751  sigma_MLE= 0.379922805263\n",
      "      fun: 36.06331761577703\n",
      " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-64.24490593,   3.13426369, -22.37210239,  47.65081698])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 105\n",
      "      nit: 12\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.92199196,  0.99999999,  0.83847218,  0.37992281])\n",
      "VCV(MLE) =  [[ 0.01692003 -0.00321064  0.00279934 -0.02074715]\n",
      " [-0.00321064  0.01679452 -0.05572713  0.02770172]\n",
      " [ 0.00279934 -0.05572713  1.0453373  -0.44003269]\n",
      " [-0.02074715  0.02770172 -0.44003269  0.21956802]]\n"
     ]
    }
   ],
   "source": [
    "# Print Results\n",
    "print('alpha_MLE=', alpha_MLE, ' rho_MLE=', rho_MLE, 'mu_MLE=', mu_MLE, ' sigma_MLE=', sigma_MLE)\n",
    "print(results1)\n",
    "\n",
    "#print(z_t(macroseries[\"w_t\"],macroseries[\"k_t\"],alpha_MLE))\n",
    "\n",
    "# Get Variance Covariance Matrix\n",
    "vcv_mle1= results1.hess_inv.todense()\n",
    "print('VCV(MLE) = ', vcv_mle1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        fun: -96.62961744707427\n",
       " lowest_optimization_result:       fun: -96.62961744707427\n",
       " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ 0.00296865, -0.00043769,  0.00017053, -0.00170814])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 190\n",
       "      nit: 27\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.46088818,  0.71644956,  9.47554935,  0.09206729])\n",
       "                    message: ['requested number of basinhopping iterations completed successfully']\n",
       "      minimization_failures: 302\n",
       "                       nfev: 82025\n",
       "                        nit: 1000\n",
       "                          x: array([ 0.46088818,  0.71644956,  9.47554935,  0.09206729])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimizer_kwargs = dict(method=\"L-BFGS-B\", \n",
    "                        bounds= ((1e-8, 1-1e-8), (-1+1e-8, 1-1e-8), (1e-8, None), (1e-8, None)),\n",
    "                        args = mle_args)\n",
    "\n",
    "results1b = opt.basinhopping(crit, params_init, \n",
    "                             minimizer_kwargs = minimizer_kwargs, niter=1000)\n",
    "alpha_MLE, rho_MLE, mu_MLE, sigma_MLE = results1b.x\n",
    "results1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Use the data $(r_t,k_t)$ and equations (4) and (5) to estimate the four parameters $(\\alpha, \\rho, \\mu, \\sigma)$ by maximum likelihood. Given a guess for the parameters $(\\alpha, \\rho, \\mu, \\sigma)$, you can use the two variables from the data $(r_t,k_t)$ and (4) to back out a series for $z_t$. You can then use equation (5) to compute the probability of each \n",
    "$$ z_t \\sim N(\\rho z_{t-1} + (1-\\rho) \\mu, \\sigma^2) $$\n",
    "The maximum likelihood estimate $(\\hat{\\alpha},\\hat{\\rho},\\hat{\\mu},\\hat{\\sigma})$ maximzies the likelihood function of that normal distribution of $z_t$'s. Report your estimates and the inverse hessian variance-covariance matrix of your estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1160.9851792952347"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define z_t using (4)\n",
    "def z_t2(r_t,k_t,alpha):\n",
    "    return np.log(r_t/(alpha*k_t**(alpha-1)))\n",
    "\n",
    "# Same as earlier\n",
    "def epsilon_t(z_t, rho,mu):\n",
    "    z_t_1 = z_t.shift()\n",
    "    z_t_1[0] = mu\n",
    "    return z_t - rho*z_t_1 - (1-rho)*mu\n",
    "\n",
    "# Define log likelihood function\n",
    "def log_lik_norm2(r_t,k_t, alpha, rho, mu, sigma):\n",
    "    epsilonvals = epsilon_t(z_t2(r_t,k_t,alpha), rho,mu)\n",
    "    #ln_pdf_vals = np.log(dst.norm_pdf(epsilonvals,0,sigma))\n",
    "    #ln_pdf_vals = -((epsilonvals)**2)/(2*sigma**2) - (1/2)*np.log(2*np.pi*sigma**2)\n",
    "    ln_pdf_vals = np.log(sts.norm.pdf(epsilonvals,loc=0,scale=sigma))\n",
    "    return ln_pdf_vals.sum()\n",
    "\n",
    "# Define Objective Function\n",
    "def crit2(params, r_t, k_t):\n",
    "    alpha, rho, mu, sigma = params\n",
    "    log_lik_val = log_lik_norm2(r_t,k_t, alpha, rho, mu, sigma)\n",
    "    return -log_lik_val\n",
    "\n",
    "### Various Tests\n",
    "#epsilon_t(z_t2(macroseries[\"r_t\"],macroseries[\"k_t\"],alpha_0), rho_0,mu_0)[1:]\n",
    "#log_lik_norm2(macroseries[\"r_t\"],macroseries[\"k_t\"], alpha_0, rho_0, mu_0, sigma_0)\n",
    "#crit(np.array([alpha_0, rho_0, mu_0, sigma_0]), macroseries[\"r_t\"],macroseries[\"k_t\"])\n",
    "#macroseries[\"r_t\"],macroseries[\"k_t\"]\n",
    "crit(np.array([0.9999999999,  0.849635638864,  1.01055911652, 0.863646623473]), macroseries[\"w_t\"],macroseries[\"k_t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run Maximum Likelihood with Gamma\n",
    "alpha_0, rho_0, mu_0, sigma_0 = 0.5, 0.3, .5, .5\n",
    "params_init2 = np.array([alpha_0, rho_0, mu_0, sigma_0])\n",
    "mle_args2 = (macroseries[\"r_t\"],macroseries[\"k_t\"])\n",
    "results2 = opt.minimize(crit2, params_init2, args=mle_args2, method = \"L-BFGS-B\",\n",
    "                        bounds = ((1e-8, 1-1e-8), (-1+1e-8, 1-1e-8), (1e-8, None), (1e-8, None)))\n",
    "alpha_MLE2, rho_MLE2, mu_MLE2, sigma_MLE2 = results2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_MLE2= 0.974533699532  rho_MLE2= 0.99999999 mu_MLE2= 0.510458281415  sigma_MLE2= 0.118906329237\n",
      "      fun: -68.60273457267111\n",
      " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 203.1278413 ,   52.29413205,    8.97118895,  -41.13039296])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 100\n",
      "      nit: 12\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.9745337 ,  0.99999999,  0.51045828,  0.11890633])\n",
      "VCV(MLE) =  <4x4 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "# Print Results\n",
    "print('alpha_MLE2=', alpha_MLE2, ' rho_MLE2=', rho_MLE2, 'mu_MLE2=', mu_MLE2, ' sigma_MLE2=', sigma_MLE2)\n",
    "print(results2)\n",
    "\n",
    "# Get Variance Covariance Matrix\n",
    "vcv_mle2 = results2.hess_inv\n",
    "print('VCV(MLE) = ', vcv_mle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        fun: -96.555128620383499\n",
       " lowest_optimization_result:       fun: -96.555128620383499\n",
       " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-0.10444836,  0.0004249 , -0.0062002 , -0.03556409])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 360\n",
       "      nit: 42\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.7198794 ,  0.45627863,  4.7677259 ,  0.09213446])\n",
       "                    message: ['requested number of basinhopping iterations completed successfully']\n",
       "      minimization_failures: 449\n",
       "                       nfev: 90935\n",
       "                        nit: 1000\n",
       "                          x: array([ 0.7198794 ,  0.45627863,  4.7677259 ,  0.09213446])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimizer_kwargs = dict(method=\"L-BFGS-B\", \n",
    "                        bounds= ((1e-8, 1-1e-8), (-1+1e-8, 1-1e-8), (1e-8, None), (1e-8, None)),\n",
    "                        args = mle_args2)\n",
    "\n",
    "results2b = opt.basinhopping(crit2, params_init2, \n",
    "                             minimizer_kwargs = minimizer_kwargs, niter=1000)\n",
    "\n",
    "results2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) According to your estimates from part (a), if investment/savings today is $k_t = 7,500,000$ and the productivity shock in the previous period is $z_{t-1} = 10$, what is the probability that the interest rate this period will be greater than $r_t =1$. That is, solve for $Pr(r_t > 1 | \\hat{\\theta},k_t, z_{t-1})$. [HINT: Use equation (4) to solve for the $z_t = z^*$ such that $r_t = 1$. Then use (5) to solve for the probability that $z_t > z^*$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_star =  9.30896287249\n",
      "Probability that r_t will be greater than 1: 1.0\n"
     ]
    }
   ],
   "source": [
    "z_star = z_t2(1,7500000,alpha_MLE)\n",
    "print('z_star = ',z_star)\n",
    "z_t_minus1 = 10\n",
    "Pr_r_t = 1 - integrate.quad(lambda x: \n",
    "                            dst.norm_pdf(x, rho_MLE*z_t_minus1 + (1-rho_MLE)*mu_MLE, sigma_MLE**2)\n",
    "                            , 0, z_star)[0]\n",
    "print('Probability that r_t will be greater than 1:', Pr_r_t)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
